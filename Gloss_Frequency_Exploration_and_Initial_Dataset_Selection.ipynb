{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j00lee/SignLingo/blob/main/Gloss_Frequency_Exploration_and_Initial_Dataset_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary Dataset Selection\n",
        "We want to investigate which gloss words appear in the English-gloss dataset so that we can focus our gloss-sign dataset on those words."
      ],
      "metadata": {
        "id": "-_naC__PGDio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counting the Gloss Frequencies of English-gloss dataset"
      ],
      "metadata": {
        "id": "soEtouR2LFpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKakoM28FxSh"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c8p3WMhgIQHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1426060-cbc6-44f2-a0f0-04a41dfa1935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV\n",
        "csv_path = '/content/drive/MyDrive/ASL Project/slt_data_clean.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Build the frequency dictionary\n",
        "gloss_freq = defaultdict(int)\n",
        "\n",
        "for sentence in df['input']:\n",
        "    words = sentence.strip().split()\n",
        "    for word in words:\n",
        "        gloss_freq[word] += 1\n",
        "\n",
        "# Save the frequency dictionary to CSV\n",
        "# Create a DataFrame from the dictionary\n",
        "gloss_freq_df = pd.DataFrame(list(gloss_freq.items()), columns=['Gloss', 'Frequency'])\n",
        "\n",
        "# Sort by 'Frequency' column in descending order\n",
        "gloss_freq_df = gloss_freq_df.sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "\n",
        "# Save to CSV in the same folder\n",
        "save_path = '/content/drive/MyDrive/ASL Project/gloss_freq.csv'\n",
        "gloss_freq_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"Gloss frequency dictionary saved to {save_path} âœ…\")"
      ],
      "metadata": {
        "id": "3fkyOEhNIT4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5eb431-09d7-44b6-ee60-e1d6f2050956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gloss frequency dictionary saved to /content/drive/MyDrive/ASL Project/gloss_freq.csv âœ…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counting the Gloss Frequencies of Gloss-sign Dataset"
      ],
      "metadata": {
        "id": "gwrH_sDELM0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "wcOikYkQLVFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvPhR-ZKLYe2",
        "outputId": "1b18c301-56fe-4885-e64c-741731b8282b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define CSV file paths\n",
        "train_path = '/content/drive/MyDrive/ASL Project/splits/train.csv'\n",
        "val_path = '/content/drive/MyDrive/ASL Project/splits/val.csv'\n",
        "test_path = '/content/drive/MyDrive/ASL Project/splits/test.csv'\n",
        "\n",
        "# Step 3: Load the CSVs\n",
        "train_df = pd.read_csv(train_path, sep=',')  # Your file is tab-separated, so use sep='\\t'\n",
        "val_df = pd.read_csv(val_path, sep=',')\n",
        "test_df = pd.read_csv(test_path, sep=',')\n",
        "\n",
        "# Debug prints\n",
        "print(train_df.columns)\n",
        "print(val_df.columns)\n",
        "print(test_df.columns)\n",
        "\n",
        "# Step 4: Function to build gloss frequency dictionary\n",
        "def build_gloss_freq(df):\n",
        "    gloss_freq = defaultdict(int)\n",
        "    for gloss in df['Gloss']:\n",
        "        gloss = gloss.strip()  # Keep full gloss name, no splitting\n",
        "        gloss_freq[gloss] += 1\n",
        "    return gloss_freq\n",
        "\n",
        "# Step 5: Build frequency dictionaries\n",
        "train_gloss_freq = build_gloss_freq(train_df)\n",
        "val_gloss_freq = build_gloss_freq(val_df)\n",
        "test_gloss_freq = build_gloss_freq(test_df)\n",
        "\n",
        "# Step 6: Build combined frequency dictionary\n",
        "# Merge the three dictionaries\n",
        "combined_gloss_freq = defaultdict(int)\n",
        "\n",
        "for gloss_dict in [train_gloss_freq, val_gloss_freq, test_gloss_freq]:\n",
        "    for gloss, freq in gloss_dict.items():\n",
        "        combined_gloss_freq[gloss] += freq\n",
        "\n",
        "# Step 7: Save each dictionary to CSV\n",
        "def save_gloss_freq(freq_dict, save_path):\n",
        "    df = pd.DataFrame(list(freq_dict.items()), columns=['Gloss', 'Frequency'])\n",
        "    df = df.sort_values(by='Frequency', ascending=False)\n",
        "    df.to_csv(save_path, index=False)\n",
        "\n",
        "# Paths to save\n",
        "train_save_path = '/content/drive/MyDrive/ASL Project/train_gloss_freq.csv'\n",
        "val_save_path = '/content/drive/MyDrive/ASL Project/val_gloss_freq.csv'\n",
        "test_save_path = '/content/drive/MyDrive/ASL Project/test_gloss_freq.csv'\n",
        "combined_save_path = '/content/drive/MyDrive/ASL Project/all_gloss_freq.csv'\n",
        "\n",
        "# Save them\n",
        "save_gloss_freq(train_gloss_freq, train_save_path)\n",
        "save_gloss_freq(val_gloss_freq, val_save_path)\n",
        "save_gloss_freq(test_gloss_freq, test_save_path)\n",
        "save_gloss_freq(combined_gloss_freq, combined_save_path)\n",
        "\n",
        "print(\"âœ… Saved gloss frequencies for train, val, test, and combined datasets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G846gdNXLb4D",
        "outputId": "6b0a1c27-6a4f-48a3-c357-e785daeef5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Participant ID', 'Video file', 'Gloss', 'ASL-LEX Code'], dtype='object')\n",
            "Index(['Participant ID', 'Video file', 'Gloss', 'ASL-LEX Code'], dtype='object')\n",
            "Index(['Participant ID', 'Video file', 'Gloss', 'ASL-LEX Code'], dtype='object')\n",
            "âœ… Saved gloss frequencies for train, val, test, and combined datasets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare the Gloss frequencies"
      ],
      "metadata": {
        "id": "hdyMJtlgQWqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Load both gloss frequency files\n",
        "gloss_freq_path = '/content/drive/MyDrive/ASL Project/gloss_freq_exploration/gloss_freq.csv'\n",
        "all_gloss_freq_path = '/content/drive/MyDrive/ASL Project/gloss_freq_exploration/all_gloss_freq.csv'\n",
        "\n",
        "gloss_df = pd.read_csv(gloss_freq_path)\n",
        "all_gloss_df = pd.read_csv(all_gloss_freq_path)\n",
        "\n",
        "# Step 3: Prepare gloss sets\n",
        "gloss_set = set(gloss_df['Gloss'])\n",
        "\n",
        "# Process all_gloss_df to remove trailing digits\n",
        "def clean_gloss(gloss):\n",
        "    return re.sub(r'\\d+$', '', gloss)  # remove trailing digits\n",
        "\n",
        "# Apply cleaning\n",
        "all_gloss_df['Cleaned Gloss'] = all_gloss_df['Gloss'].apply(clean_gloss)\n",
        "all_gloss_set = set(all_gloss_df['Cleaned Gloss'])\n",
        "\n",
        "# Step 4: Compare sets\n",
        "common_glosses = gloss_set & all_gloss_set      # intersection\n",
        "only_in_gloss_freq = gloss_set - all_gloss_set  # in gloss_freq.csv but not in all_gloss_freq.csv\n",
        "only_in_all_gloss = all_gloss_set - gloss_set   # in all_gloss_freq.csv but not in gloss_freq.csv\n",
        "\n",
        "# Step 5: Print some basic stats\n",
        "print(f\"Total glosses in English-gloss dataset: {len(gloss_set)}\")\n",
        "print(f\"Total glosses in sign-video dataset: {len(all_gloss_set)}\")\n",
        "print(f\"Common glosses: {len(common_glosses)}\")\n",
        "print(f\"Glosses only in English-gloss dataset: {len(only_in_gloss_freq)}\")\n",
        "print(f\"Glosses only in sign-video dataset: {len(only_in_all_gloss)}\")\n",
        "\n",
        "# (Optional) See a few examples\n",
        "print(\"\\nSome glosses only in English-gloss dataset:\")\n",
        "print(list(only_in_gloss_freq)[:10])\n",
        "\n",
        "print(\"\\nSome glosses only in sign-video dataset:\")\n",
        "print(list(only_in_all_gloss)[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44PA03EgQdKC",
        "outputId": "01ae9741-4d94-46fc-f3a1-dde1b0206620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Total glosses in English-gloss dataset: 4690\n",
            "Total glosses in sign-video dataset: 2301\n",
            "Common glosses: 1216\n",
            "Glosses only in English-gloss dataset: 3474\n",
            "Glosses only in sign-video dataset: 1085\n",
            "\n",
            "Some glosses only in English-gloss dataset:\n",
            "['SHE-MEET-I', 'T-T-Y', 'FIFTY', 'E-L-F', 'THANKSGIVING++', 'SUPER', 'FIRE++', 'THINK-SAME', 'LB', 'COME-TO']\n",
            "\n",
            "Some glosses only in sign-video dataset:\n",
            "['TOBACCO', 'WEWILLSEE', 'ICECREAM', 'VALIDATE', 'KING', 'CAMEL', 'STICKY', 'FROMTHENON', 'PHILOSOPHY', 'DONTMIND']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 6: Save to TXT files\n",
        "output_folder = '/content/drive/MyDrive/ASL Project/gloss_freq_exploration/'\n",
        "\n",
        "# Save glosses only in English-gloss dataset\n",
        "with open(output_folder + 'only_in_gloss_freq.txt', 'w') as f:\n",
        "    for gloss in sorted(only_in_gloss_freq):\n",
        "        f.write(gloss + '\\n')\n",
        "\n",
        "# Save glosses only in sign-video dataset (after cleaning)\n",
        "with open(output_folder + 'only_in_all_gloss.txt', 'w') as f:\n",
        "    for gloss in sorted(only_in_all_gloss):\n",
        "        f.write(gloss + '\\n')\n",
        "\n",
        "# Save common glosses\n",
        "with open(output_folder + 'common_glosses.txt', 'w') as f:\n",
        "    for gloss in sorted(common_glosses):\n",
        "        f.write(gloss + '\\n')"
      ],
      "metadata": {
        "id": "wVB9jmtjQgb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We Select our Dataset\n",
        "Using the 1216 shared glosses"
      ],
      "metadata": {
        "id": "-_yvHS9PR86r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "\n",
        "# === Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# === Step 2: Define Paths\n",
        "base_folder = '/content/drive/MyDrive/ASL Project/'\n",
        "splits_folder = base_folder + 'splits/'\n",
        "filtered_folder = base_folder + 'filtered splits/'\n",
        "common_glosses_path = base_folder + 'gloss_freq_exploration/common_glosses.csv'\n",
        "\n",
        "# Create the 'filtered splits' folder if it doesn't exist\n",
        "os.makedirs(filtered_folder, exist_ok=True)\n",
        "\n",
        "train_path = splits_folder + 'train.csv'\n",
        "val_path = splits_folder + 'val.csv'\n",
        "test_path = splits_folder + 'test.csv'\n",
        "\n",
        "# === Step 3: Load common glosses\n",
        "common_glosses_df = pd.read_csv(common_glosses_path)\n",
        "common_glosses_set = set(common_glosses_df['Gloss'])\n",
        "\n",
        "# === Step 4: Function to clean gloss (remove trailing digits)\n",
        "def clean_gloss(gloss):\n",
        "    return re.sub(r'\\d+$', '', gloss)\n",
        "\n",
        "# === Step 5: Function to filter a dataset\n",
        "def filter_dataset(df):\n",
        "    # Create a temporary column with cleaned glosses\n",
        "    df['Cleaned Gloss'] = df['Gloss'].apply(clean_gloss)\n",
        "\n",
        "    # Keep rows where cleaned gloss is in common_glosses_set\n",
        "    filtered_df = df[df['Cleaned Gloss'].isin(common_glosses_set)].copy()\n",
        "\n",
        "    # Drop the temporary 'Cleaned Gloss' column\n",
        "    filtered_df = filtered_df.drop(columns=['Cleaned Gloss'])\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "# === Step 6: Load datasets\n",
        "train_df = pd.read_csv(train_path)\n",
        "val_df = pd.read_csv(val_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# === Step 7: Filter datasets\n",
        "train_filtered = filter_dataset(train_df)\n",
        "val_filtered = filter_dataset(val_df)\n",
        "test_filtered = filter_dataset(test_df)\n",
        "\n",
        "# === Step 8: Save filtered datasets\n",
        "train_filtered.to_csv(filtered_folder + 'train_filtered.csv', index=False)\n",
        "val_filtered.to_csv(filtered_folder + 'val_filtered.csv', index=False)\n",
        "test_filtered.to_csv(filtered_folder + 'test_filtered.csv', index=False)\n",
        "\n",
        "# === Step 9: Count number of videos\n",
        "print(\"âœ… Filtered datasets saved!\\n\")\n",
        "print(\"ðŸ“Š Number of videos after filtering:\")\n",
        "print(f\"Train: {len(train_filtered)} videos\")\n",
        "print(f\"Val: {len(val_filtered)} videos\")\n",
        "print(f\"Test: {len(test_filtered)} videos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfc-rvL5SChg",
        "outputId": "d19fd596-5b15-4d38-b84f-03c52d99a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Filtered datasets saved!\n",
            "\n",
            "ðŸ“Š Number of videos after filtering:\n",
            "Train: 21240 videos\n",
            "Val: 5446 videos\n",
            "Test: 17639 videos\n"
          ]
        }
      ]
    }
  ]
}